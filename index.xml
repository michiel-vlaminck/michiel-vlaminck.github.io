<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Michiel Vlaminck</title>
    <link>https://michiel-vlaminck.github.io/</link>
    <description>Recent content on Michiel Vlaminck</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 21 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://michiel-vlaminck.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AI-based anomaly detection in PV power plants based on thermal imaging</title>
      <link>https://michiel-vlaminck.github.io/theses/pv-anomaly-detection/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/pv-anomaly-detection/</guid>
      <description>Problem statement Photovoltaic (PV) technology is one of the key-drivers of the transition towards a fully renewable-based energy system. However, current PV power plants use complex, highly customized monitoring systems that require high maintenance costs and a lot of manual intervention. As a result, numerous PV plants today operate without monitoring. The PV industry, therefore, needs a fully automated system that is able to detect anomalies, including hotspots, potential induced defects (PIDs) or issues on bypass substrings, diodes, strings or junction boxes.</description>
    </item>
    
    <item>
      <title>Drone Imagery Anonymization using AI</title>
      <link>https://michiel-vlaminck.github.io/theses/ai-anonymization/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/ai-anonymization/</guid>
      <description>Problem statement The GDPR introduced new regulations on how to process and handle personal data. As such, meeting the GDPR requirements is key in selling software applications to customers. The anonymization of textual data is largely accepted as something that is possible, but this is not something that is true for images. For example sometimes a face detection algorithm fails and a face is not blurred. Further, vehicles are often recognizable not just by their number plates but also by logos or other characteristics.</description>
    </item>
    
    <item>
      <title>Multi-agent visual SLAM</title>
      <link>https://michiel-vlaminck.github.io/theses/multi-agent-slam/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/multi-agent-slam/</guid>
      <description>Problem statement With the ever-growing abundance of cameras in cars, smartphones and other mobile computing platforms, there has been a lot of progress in the visual flavor of Simultaneous Localization And Mapping (SLAM) [Engel et al. 2015, Mur-Artal et al. 2016]. However, these systems are often designed for single-agent scenarios. For Belgian Defence and partner institutions, extending these systems to allow multi-agent operation with limited computational power would bring a lot of value.</description>
    </item>
    
    <item>
      <title>Person detection in challenging conditions: combining RGB and thermal imaging on wearable devices</title>
      <link>https://michiel-vlaminck.github.io/theses/person-detection/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/person-detection/</guid>
      <description>Detecting persons possibly hidden in challenging environments with smoke, fog or in the dark is a complex task for the dismounted soldier in tactical operations as well as for firefighters in hazardous, urgency situations. Miniaturization has made more and more computer vision applications on lightweight, wearable devices possible. With the advent of smartglasses, these systems may be operated in a hands-free manner. This opens the way for a whole new series of use cases in operational scenarios.</description>
    </item>
    
    <item>
      <title>Simultaneous Localization and Mapping (SLAM) using Differentiable Programming</title>
      <link>https://michiel-vlaminck.github.io/theses/dp-slam/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/dp-slam/</guid>
      <description>Problem statement Simultaneous Localization and Mapping (SLAM) is a computer-vision technique that allows robots and vehicles to autonomously construct or update the map of the environment. In particular, dense visual SLAM achieves a high quality dense reconstruction, which is useful for accurate real-time tracking, 3D scene extraction and modelling. Based on a high quality SLAM, it becomes easier to develop applications for automatic robot interactions with the environment and autonomous driving.</description>
    </item>
    
    <item>
      <title>Talk at AI4Growth Industrial AI Day</title>
      <link>https://michiel-vlaminck.github.io/posts/ai4growth/</link>
      <pubDate>Fri, 04 Sep 2020 22:07:06 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/ai4growth/</guid>
      <description>On September 17th I will give a yalk at the AI4Growth Industrial IA Day - as part of the ECML PKDD conference - on the work I have been doing on aerial inspection of PV power plants.</description>
    </item>
    
    <item>
      <title>Successfully defended my PhD</title>
      <link>https://michiel-vlaminck.github.io/posts/phd-defense/</link>
      <pubDate>Wed, 25 Mar 2020 18:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/phd-defense/</guid>
      <description>Today I successfully defended my PhD entitled &amp;ldquo;3D mapping using active depth sensors&amp;rdquo; [link]. Due to the COVID-19 measures, I was obligated to do defense remotely, from home. Fortunately, technology didn&amp;rsquo;t let me down and everything went fine. I can call myself a doctor in computer science engineering from now on. Thanks to everyone who helped me during the past 6 years!
I also owe a special word of thanks to my girlfriend, who surprised me with a self-assembled PhD hat, for which I am very grateful!</description>
    </item>
    
    <item>
      <title>ANALYST PV</title>
      <link>https://michiel-vlaminck.github.io/projects/analyst-pv/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/analyst-pv/</guid>
      <description>The goal of this project is to provide tools for fault localization, power loss quantification and improved diagnostics of PV power plants. A more efficient detection, diagnosis and localization of the fault will lead to a reduced time during which the fault can impact production. More information can be found on the project website.
My work in the project consists of developing image processing techniques to detect and classify anomalies that occur on solar panels including bypass substrings, junction box issues, diode issues, string issues and potential induced defects (PID).</description>
    </item>
    
    <item>
      <title>COMP4DRONES</title>
      <link>https://michiel-vlaminck.github.io/projects/comp4drones/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/comp4drones/</guid>
      <description>COMP4DRONES is a European project that aims to provide a framework of key technologies to facilitate safe and autonomous drones. It will ease the development of new applications and functionalities on the field of transport, construction, surveillance and inspection, logistics and agriculture. More information can be found on the project website. The project is in collaboration with the HSI team of imec and the company Airobot.
My work in the project focuses on the use case of inspection of critical infrastructure, such as off-shore wind turbines or bridges, by means of hyperspectral imaging.</description>
    </item>
    
    <item>
      <title>Presentation at CRV 2018</title>
      <link>https://michiel-vlaminck.github.io/posts/presentation-crv-2018/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/presentation-crv-2018/</guid>
      <description>Today I gave a presentation at the Conference on Computer and Robot Vision (CRV), in Toronto, Canada.</description>
    </item>
    
    <item>
      <title>Demo at Ghent Light Festival 2018</title>
      <link>https://michiel-vlaminck.github.io/posts/light-festival-2018/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/light-festival-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Demo at 200 years UGent celebration</title>
      <link>https://michiel-vlaminck.github.io/posts/200-years-ugent/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/200-years-ugent/</guid>
      <description>To celebrate its 200 year existence, UGent organized an event on October 8th, to showcase its daily activities to the general public. I gave a demonstration of the 3D mapping robot I developed during my PhD.</description>
    </item>
    
    <item>
      <title>Invited speaker MPI Tubingen</title>
      <link>https://michiel-vlaminck.github.io/posts/invited-speaker-mpi/</link>
      <pubDate>Sun, 20 Aug 2017 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/invited-speaker-mpi/</guid>
      <description>Today I gave a presentation at the Max Planck Institute (MPI) Tubingen in Germany [link]. I presented my work regarding 3D mapping using lidar scanners. I gave an overview of the SLAM problem and its main challenges: robustness, accuracy and processing speed. Regarding robustness and accuracy, I explained a better point cloud representation based on resampling and surface reconstruction. I also pointed out how it can be incorporated in an ICP-based scan matching technique and explained globally consistent mapping using loop closures.</description>
    </item>
    
    <item>
      <title>Presentation at SPIE 2017</title>
      <link>https://michiel-vlaminck.github.io/posts/presentation-spie-2017/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/presentation-spie-2017/</guid>
      <description>Today I gave a presentation at the SPIE conference in San Diego, USA.</description>
    </item>
    
    <item>
      <title>Demo at ITF 2017</title>
      <link>https://michiel-vlaminck.github.io/posts/demo-itf-2017/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/demo-itf-2017/</guid>
      <description>Today I gave a presentation at the SPIE conference in San Diego, USA.</description>
    </item>
    
    <item>
      <title>Presentation at MVA 2017</title>
      <link>https://michiel-vlaminck.github.io/posts/presentation-mva-2017/</link>
      <pubDate>Tue, 09 May 2017 00:00:00 +0200</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/posts/presentation-mva-2017/</guid>
      <description>Today I gave a presentation at the Conference on Machine Vision Applications (MVA) in Nagoya, Japan. The paper I presented is entitled &amp;ldquo;Multi-resolution ICP for the Efficient Registration of Point clouds based Octrees&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>ARIA</title>
      <link>https://michiel-vlaminck.github.io/projects/aria/</link>
      <pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/aria/</guid>
      <description>The ICON project Augmented Reality for Industrial Applications was the follow-up project of GIPA. This time, the goal was to develop a guidance application for maintenance tasks on complex industrial machinery. By means of proof of concept we focused on the replacement of an oil filter in a cooling container of the company Evonik in Antwerp. More specifically, we made it possible for a layman to be guided using visual cues while wearing a head mounted device.</description>
    </item>
    
    <item>
      <title>3D mapping using active depth sensors</title>
      <link>https://michiel-vlaminck.github.io/research/3d-mapping/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/research/3d-mapping/</guid>
      <description>All this means that a system is needed that is able to perform 3D mapping - and thus also 3D positioning - based on sensors that are able to perceive the environment, such as cameras or depth sensors. In the scientific literature, this problem is also known as simultaneous localization and mapping or SLAM as it involves both the precise localization of the robot and the mapping of the environment at the same time.</description>
    </item>
    
    <item>
      <title>GIPA</title>
      <link>https://michiel-vlaminck.github.io/projects/gipa/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/gipa/</guid>
      <description>The ICON project GIPA or Generic Interoperability Platform for Augmented reality applications took place in 2014 and 2015. The aim was to develop a generic AR platform able to serve a whole range of applications including but not limited to remote collaboration, remote expert aid, serious gaming and training, critical infrastructure management and disaster or crisis support. As an example use case, we focused on the application of &amp;lsquo;as-built-as-planned&amp;rsquo;, in which the goal is to give architects the ability to verify whether or not a construction is built according to their plans.</description>
    </item>
    
  </channel>
</rss>