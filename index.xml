<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Michiel Vlaminck</title>
    <link>https://michiel-vlaminck.github.io/</link>
    <description>Recent content on Michiel Vlaminck</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 24 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://michiel-vlaminck.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>An Incremental Approach for Creating Global Land Cover Maps</title>
      <link>https://michiel-vlaminck.github.io/theses/land-cover-maps/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/land-cover-maps/</guid>
      <description>Problem statement TomTom has recently created a global Land Cover (LC) map at mid-low scale by applying machine learning technologies on satellite imagery from the Sentinel 2 mission [link]. As an example, a Land Cover map of India from 2005 is shown below. To create the first version of the map, TomTom conducted a large-scale training data collection operation. The next step is to perform a fully automated and repeatable global LC mapping for small scale, in a cost-effective way.</description>
    </item>
    
    <item>
      <title>Autonomous racecar analytics using drones</title>
      <link>https://michiel-vlaminck.github.io/theses/racecar-analytics-drones/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/racecar-analytics-drones/</guid>
      <description>Problem statement Autonomous racecars in the formula student competition should be able to race on unknown tracks without having access to precise external navigation tools such as GPS. Therefore, the cars need to build up an internal track layout via sensing of the surrounding environment using either a camera and/or a lidar scanner. The accuracy of this technique is hard to validate since the ground truth is often not measured.</description>
    </item>
    
    <item>
      <title>Different localization flavors during autonomous racing</title>
      <link>https://michiel-vlaminck.github.io/theses/localization-racing/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/localization-racing/</guid>
      <description>Problem statement During autonomous racing in the formula student racing competition, at least 40m of the track in front of the car should be observed in order to provide the best possible racing lines. However, current sensing only provides 10m of accurate track layout. Therefore, most teams use their first lap to create an internal mapping that is then used for calculating the lines in the next laps. The cars should then be able to locate themselves in this internal map to have more prior knowledge of the upcoming race track.</description>
    </item>
    
    <item>
      <title>Garment transfer using GANs</title>
      <link>https://michiel-vlaminck.github.io/theses/garment-gan/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/garment-gan/</guid>
      <description>Problem statement Ever wonder how you would look in a certain t-shirt or pair of shoes without having to try it on? Well, that’s the problem that garment transfer is trying to solve. Given an image of a person and piece of clothing as input, the goal is to get a photo-realistic picture of that person wearing that piece of clothing.
Garment transfer existed as science fiction for a long time, but only recently became possible to solve with the advent of GANs.</description>
    </item>
    
    <item>
      <title>Image analysis to monitor the spreading processes on a combine harvester</title>
      <link>https://michiel-vlaminck.github.io/theses/spreading-harvester/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/spreading-harvester/</guid>
      <description>Problem statement For many years, combine harvesters (dutch: maaidorser) are used to harvest grain crops, wheat, barley, rye, corn, soybeans, peas …. The machine cuts the crop and separates the grain kernels from the plant. The residue (e.g. straw) is in large parts of the world chopped into small parts and spread over the field. This residue subsequently acts as fertilizer for the next crop cycle. It is of paramount importance that the residue is spread evenly in order for it to degrade properly and fertilize uniformly.</description>
    </item>
    
    <item>
      <title>Using augmented reality on a smartphone to aid with machine maintenance</title>
      <link>https://michiel-vlaminck.github.io/theses/ar-maintenance/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/ar-maintenance/</guid>
      <description>Problem statement CNH Industrial designs, manufactures and sells combine harvesters from Zedelgem, Belgium. A combine harvester (dutch: maaidorser) is what we call a factory on wheels. It is used to harvest grain crops, wheat, barley, rye, corn, soybeans, peas,… This is a large and complex machine with lots of moving parts. For the operator of the machine it is hard to learn every little detail of the machine.
Goal In this thesis we want to build an app for a smartphone that would aid the operator in locating certain parts on the machine for maintenance and error-tracking.</description>
    </item>
    
    <item>
      <title>Virtual Reality-based annotation environment for drone images to implement 3D AI-based defect detection on digital twins</title>
      <link>https://michiel-vlaminck.github.io/theses/defect-detection/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/defect-detection/</guid>
      <description>Problem statement Container terminals are losing money when critical assets like container cranes experience unexpected downtime due to defects (e.g. cracks, corrosion). The cost due to operational losses and penalties if a vessel cannot unload go up to 5 Mio EUR per day. Regular inspections by experts are critical to gathering the right maintenance insights to take the needed preventive maintenance actions. Due to the limited availability of experienced inspectors worldwide, there is a high need for tools to support these inspectors and improve the inspection efficiency.</description>
    </item>
    
    <item>
      <title>AI-based anomaly detection in PV power plants based on thermal imaging</title>
      <link>https://michiel-vlaminck.github.io/theses/pv-anomaly-detection/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/pv-anomaly-detection/</guid>
      <description>Problem statement Photovoltaic (PV) technology is one of the key-drivers of the transition towards a fully renewable-based energy system. However, current PV power plants use complex, highly customized monitoring systems that require high maintenance costs and a lot of manual intervention. As a result, numerous PV plants today operate without monitoring. The PV industry, therefore, needs a fully automated system that is able to detect anomalies, including hotspots, potential induced defects (PIDs) or issues on bypass substrings, diodes, strings or junction boxes.</description>
    </item>
    
    <item>
      <title>Drone Imagery Anonymization using AI</title>
      <link>https://michiel-vlaminck.github.io/theses/ai-anonymization/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/ai-anonymization/</guid>
      <description>Problem statement The GDPR introduced new regulations on how to process and handle personal data. As such, meeting the GDPR requirements is key in selling software applications to customers. The anonymization of textual data is largely accepted as something that is possible, but this is not something that is true for images. For example sometimes a face detection algorithm fails and a face is not blurred. Further, vehicles are often recognizable not just by their number plates but also by logos or other characteristics.</description>
    </item>
    
    <item>
      <title>Multi-agent visual SLAM</title>
      <link>https://michiel-vlaminck.github.io/theses/multi-agent-slam/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/multi-agent-slam/</guid>
      <description>Problem statement With the ever-growing abundance of cameras in cars, smartphones and other mobile computing platforms, there has been a lot of progress in the visual flavor of Simultaneous Localization And Mapping (SLAM) [Engel et al. 2015, Mur-Artal et al. 2016]. However, these systems are often designed for single-agent scenarios. For Belgian Defence and partner institutions, extending these systems to allow multi-agent operation with limited computational power would bring a lot of value.</description>
    </item>
    
    <item>
      <title>Person detection in challenging conditions: combining RGB and thermal imaging on wearable devices</title>
      <link>https://michiel-vlaminck.github.io/theses/person-detection/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/person-detection/</guid>
      <description>Detecting persons possibly hidden in challenging environments with smoke, fog or in the dark is a complex task for the dismounted soldier in tactical operations as well as for firefighters in hazardous, urgency situations. Miniaturization has made more and more computer vision applications on lightweight, wearable devices possible. With the advent of smartglasses, these systems may be operated in a hands-free manner. This opens the way for a whole new series of use cases in operational scenarios.</description>
    </item>
    
    <item>
      <title>Simultaneous Localization and Mapping (SLAM) using Differentiable Programming</title>
      <link>https://michiel-vlaminck.github.io/theses/dp-slam/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/theses/dp-slam/</guid>
      <description>Problem statement Simultaneous Localization and Mapping (SLAM) is a computer-vision technique that allows robots and vehicles to autonomously construct or update the map of the environment. In particular, dense visual SLAM achieves a high quality dense reconstruction, which is useful for accurate real-time tracking, 3D scene extraction and modelling. Based on a high quality SLAM, it becomes easier to develop applications for automatic robot interactions with the environment and autonomous driving.</description>
    </item>
    
    <item>
      <title>ANALYST PV</title>
      <link>https://michiel-vlaminck.github.io/projects/analyst-pv/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/analyst-pv/</guid>
      <description>The goal of this project is to provide tools for fault localization, power loss quantification and improved diagnostics of PV power plants. A more efficient detection, diagnosis and localization of the fault will lead to a reduced time during which the fault can impact production. More information can be found on the project website. The project is in close collaboration with the company Sitemark, who provided all the data used to conduct this research.</description>
    </item>
    
    <item>
      <title>COMP4DRONES</title>
      <link>https://michiel-vlaminck.github.io/projects/comp4drones/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/comp4drones/</guid>
      <description>COMP4DRONES is a European project that aims to provide a framework of key technologies to facilitate safe and autonomous drones. It will ease the development of new applications and functionalities on the field of transport, construction, surveillance and inspection, logistics and agriculture. More information can be found on the project website. The project is in collaboration with the HSI team of imec and the company Airobot.
My work in the project focuses on the use case of inspection of critical infrastructure, such as off-shore wind turbines or bridges, by means of hyperspectral imaging.</description>
    </item>
    
    <item>
      <title>ARIA</title>
      <link>https://michiel-vlaminck.github.io/projects/aria/</link>
      <pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/aria/</guid>
      <description>The ICON project Augmented Reality for Industrial Applications was the follow-up project of GIPA. This time, the goal was to develop a guidance application for maintenance tasks on complex industrial machinery. By means of proof of concept we focused on the replacement of an oil filter in a cooling container of the company Evonik in Antwerp. More specifically, we made it possible for a layman to be guided using visual cues while wearing a head mounted device.</description>
    </item>
    
    <item>
      <title>3D mapping using active depth sensors</title>
      <link>https://michiel-vlaminck.github.io/research/3d-mapping/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/research/3d-mapping/</guid>
      <description>During my PhD I developed a system that is able to perform 3D mapping - and thus also 3D positioning - based on sensors that are able to perceive the environment, such as lidar scanners or time-of-flight cameras. In the scientific literature, this problem is also known as simultaneous localization and mapping or SLAM as it involves both the precise localization of the robot and the mapping of the environment at the same time.</description>
    </item>
    
    <item>
      <title>GIPA</title>
      <link>https://michiel-vlaminck.github.io/projects/gipa/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://michiel-vlaminck.github.io/projects/gipa/</guid>
      <description>The ICON project GIPA or Generic Interoperability Platform for Augmented reality applications took place in 2014 and 2015. The aim was to develop a generic AR platform able to serve a whole range of applications including but not limited to remote collaboration, remote expert aid, serious gaming and training, critical infrastructure management and disaster or crisis support. As an example use case, we focused on the application of &amp;lsquo;as-built-as-planned&amp;rsquo;, in which the goal is to give architects the ability to verify whether or not a construction is built according to their plans.</description>
    </item>
    
  </channel>
</rss>
