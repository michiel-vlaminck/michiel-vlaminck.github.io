<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Michiel Vlaminck">
    <meta name="description" content="Problem statement Simultaneous Localization and Mapping (SLAM) is a computer-vision technique that allows robots and vehicles to autonomously construct or update the map of the environment. In particular, dense visual SLAM achieves a high quality dense reconstruction, which is useful for accurate real-time tracking, 3D scene extraction and modelling. Based on a high quality SLAM, it becomes easier to develop applications for automatic robot interactions with the environment and autonomous driving.">
    <meta name="keywords" content="blog,developer,personal">

    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Simultaneous Localization and Mapping (SLAM) using Differentiable Programming"/>
<meta name="twitter:description" content="Problem statement Simultaneous Localization and Mapping (SLAM) is a computer-vision technique that allows robots and vehicles to autonomously construct or update the map of the environment. In particular, dense visual SLAM achieves a high quality dense reconstruction, which is useful for accurate real-time tracking, 3D scene extraction and modelling. Based on a high quality SLAM, it becomes easier to develop applications for automatic robot interactions with the environment and autonomous driving."/>

    <meta property="og:title" content="Simultaneous Localization and Mapping (SLAM) using Differentiable Programming" />
<meta property="og:description" content="Problem statement Simultaneous Localization and Mapping (SLAM) is a computer-vision technique that allows robots and vehicles to autonomously construct or update the map of the environment. In particular, dense visual SLAM achieves a high quality dense reconstruction, which is useful for accurate real-time tracking, 3D scene extraction and modelling. Based on a high quality SLAM, it becomes easier to develop applications for automatic robot interactions with the environment and autonomous driving." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://michiel-vlaminck.github.io/theses/dp-slam/" /><meta property="article:section" content="theses" />
<meta property="article:published_time" content="2020-09-21T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2020-09-21T00:00:00&#43;00:00" />



    
      <base href="https://michiel-vlaminck.github.io/theses/dp-slam/">
    
    <title>
  Simultaneous Localization and Mapping (SLAM) using Differentiable Programming · Michiel Vlaminck
</title>

    
      <link rel="canonical" href="https://michiel-vlaminck.github.io/theses/dp-slam/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.3219ef62ae52679b7a9c19043171c3cd9f523628c2a65f3ef247ee18836bc90b.css" integrity="sha256-MhnvYq5SZ5t6nBkEMXHDzZ9SNijCpl8&#43;8kfuGINryQs=" crossorigin="anonymous" media="screen" />
    

    

    

    
      <link rel="stylesheet" href="/css/custom.css" />
    

    

    <link rel="icon" type="image/png" href="https://michiel-vlaminck.github.io/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://michiel-vlaminck.github.io/img/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.81.0" />
  </head>

  
  
  <body class="colorscheme-light"
        onload=""
  >
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Michiel Vlaminck
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/research/">Research</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/publications/">Publications</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/teaching/">Teaching</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/theses/">Theses</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/contact/">Contact me</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>Simultaneous Localization and Mapping (SLAM) using Differentiable Programming</h1>
    </header>

    <h2 id="problem-statement">Problem statement</h2>
<p>Simultaneous Localization and Mapping (SLAM) is a computer-vision technique that allows robots and vehicles to autonomously construct or update the map of the environment. In particular, dense visual SLAM achieves a high quality dense reconstruction, which is useful for accurate real-time tracking, 3D scene extraction and modelling. Based on a high quality SLAM, it becomes easier to develop applications for automatic robot interactions with the environment and autonomous driving.</p>
<p>Monocular SLAM aims at reconstructing the camera pose and depth map from a single RGB camera source. This problem is significantly more difficult than in SLAM methods that have a depth map available (RGB+D) through structured light or time-of-flight. However, monocular SLAM has a vast number of applications in real-life, e.g., smartphones do no longer require a special depth sensor.</p>
<p><img src="../../img/theses/slam-1.png" alt="PV anomalies">   <img src="../../img/theses/slam-2.jpg" alt="PV anomalies"></p>
<p>Recently, there has been some research on deep learning based dense monocular SLAM methods [1]. This approach consists of training a neural network to perform depth prediction and semantic segmentation based on a single image and subsequently to refine the depth image so that frame matching constraints are not violated while simultaneously updating the camera pose.</p>
<p>Differentiable programming (DP) is a relatively new programming paradigm that is considered (by some) to be Deep Learning 2.0 due to its applicability to code that is not only describing neural network structures. This gives new perspectives of incorporating deep learning techniques in SLAM methods, potentially making the methods faster, requiring less training data etc.</p>
<h2 id="goal">Goal</h2>
<p>The goal of this thesis is to study SLAM from a DP point of view. As a first step, correspondences between subsequent frames are found through traditional block matching. The resulting motion vector field is then used to obtain a first estimate of the camera pose and depth image, by minimizing a cost function through DP. In subsequent steps the camera pose and depth estimates will be iteratively refined using a convolutional neural network (CNN). A challenge here is to investigate computationally efficient hierarchical techniques that can run, e.g., in real-time on a GPU.</p>
<p>For this thesis, the programming and development environment Quasar will be available, which already supports differentiable programming and which allows hybrid CPU-GPU programming in a hardware agnostic way. Possible programming languages to be used during this thesis are: Quasar, Python, Matlab and/or C++.</p>
<p>This thesis was conducted by <strong>Wannes Van Leemput</strong> (<a href="mailto:Wannes.VanLeemput@UGent.be">Wannes.VanLeemput@UGent.be</a>).</p>
<h2 id="references">References</h2>
<p>[1] Tateno K, TombariF, LainaI, et al. CNN-SLAM: Real-time dense monocular slam with learned depth prediction. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 6243-6252</p>
<p>[2] Zhao, Cheng, et al. &ldquo;Learning monocular visual odometry with dense 3D mapping from dense 3D flow.&rdquo; 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018.</p>

  </article>
</section>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js" id="MathJax-script"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'], ['\\(', '\\)']
        ],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>

      </div>

      
  <footer class="footer">
    <section class="container">
      
        <p>Computer science engineer & PhD in 3D computer vision with a strong interest in artificial intelligence and autonomous robots.</p>
      
      
        ©
        
          2020 -
        
        2022
         Michiel Vlaminck 
      
      
      
    </section>
  </footer>

    </main>

    

    

    

  </body>

</html>
