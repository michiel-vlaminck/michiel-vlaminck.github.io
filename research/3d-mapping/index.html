<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Michiel Vlaminck">
    <meta name="description" content="During my PhD I developed a system that is able to perform 3D mapping - and thus also 3D positioning - based on sensors that are able to perceive the environment, such as cameras or depth sensors. In the scientific literature, this problem is also known as simultaneous localization and mapping or SLAM as it involves both the precise localization of the robot and the mapping of the environment at the same time.">
    <meta name="keywords" content="blog,developer,personal">

    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="3D mapping using active depth sensors"/>
<meta name="twitter:description" content="During my PhD I developed a system that is able to perform 3D mapping - and thus also 3D positioning - based on sensors that are able to perceive the environment, such as cameras or depth sensors. In the scientific literature, this problem is also known as simultaneous localization and mapping or SLAM as it involves both the precise localization of the robot and the mapping of the environment at the same time."/>

    <meta property="og:title" content="3D mapping using active depth sensors" />
<meta property="og:description" content="During my PhD I developed a system that is able to perform 3D mapping - and thus also 3D positioning - based on sensors that are able to perceive the environment, such as cameras or depth sensors. In the scientific literature, this problem is also known as simultaneous localization and mapping or SLAM as it involves both the precise localization of the robot and the mapping of the environment at the same time." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://michiel-vlaminck.github.io/research/3d-mapping/" />
<meta property="article:published_time" content="2014-01-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2014-01-01T00:00:00+00:00" />


    
      <base href="https://michiel-vlaminck.github.io/research/3d-mapping/">
    
    <title>
  3D mapping using active depth sensors · Michiel Vlaminck
</title>

    
      <link rel="canonical" href="https://michiel-vlaminck.github.io/research/3d-mapping/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.3219ef62ae52679b7a9c19043171c3cd9f523628c2a65f3ef247ee18836bc90b.css" integrity="sha256-MhnvYq5SZ5t6nBkEMXHDzZ9SNijCpl8&#43;8kfuGINryQs=" crossorigin="anonymous" media="screen" />
    

    

    

    
      <link rel="stylesheet" href="/css/custom.css" />
    

    

    <link rel="icon" type="image/png" href="https://michiel-vlaminck.github.io/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://michiel-vlaminck.github.io/img/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.73.0" />
  </head>

  
  
  <body class="colorscheme-light"
        onload=""
  >
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      Michiel Vlaminck
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/research/">Research</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/publications/">Publications</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/teaching/">Teaching</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/theses/">Theses</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://michiel-vlaminck.github.io/contact/">Contact me</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>3D mapping using active depth sensors</h1>
    </header>

    <p>During my PhD I developed a system that is able to perform 3D mapping - and thus also 3D positioning - based on sensors that are able to perceive the environment, such as cameras or depth sensors. In the scientific literature, this problem is also known as <strong>simultaneous localization and mapping</strong> or <strong>SLAM</strong> as it involves both the precise localization of the robot and the mapping of the environment at the same time.</p>
<p><img src="../../img/3d-mapping/indoor-3d-mapping.png" alt="Indoor 3D mapping"></p>
<p>Current 3D mapping solutions are either too slow or they are insufficiently accurate or robust. Moreover, they are often still relying on external positioning, which makes them unsuitable in a lot of circumstances. In this work, we invented techniques that allow to build a 3D map of the environment in <strong>real-time</strong> and solely using data captured with active depth sensors.</p>
<p>The research contributions of this work focus on three major improvements in the domain of 3D mapping and localization. First, we developed techniques to <strong>accelerate the mapping process</strong> making it possible to reconstruct the environment in high detail in real-time. This means that the data is aggregated into a 3D map at the rate it comes in, such that it can be used by autonomous robots to navigate themselves within the environment. It also allows AR applications to use the 3D map to enrich the field of view of the user with virtual objects. Thanks to the high level of detail of the reconstructions the system can also be used for real-time inspection purposes or real-time damage assessment.</p>
<p>Second, we focused on algorithms that <strong>improve the accuracy of mobile 3D mapping</strong> to a level above what is available in the academic literature. In addition, we developed techniques to dynamically adjust the level of detail, making it possible to tune the speed versus accuracy trade-off depending on the use case or the `circumstances&rsquo;, e.g. in case of resource-constrained operating platforms.</p>
<p>Third, we focused on the <strong>robustness of the 3D SLAM process</strong> in order to avoid situations in which the <em>tracking</em> is lost due to failures in one of the different sub-processes. Below we explain the main research contributions of this work.</p>
<h2 id="liborg">Liborg</h2>
<p>Besides the development of efficient 3D mapping algorithms, we also needed an efficient acquisition platform to easily collect data from. To that end, we started with the development of a rover that can map its environment. In a later stage, we also made it possible to perform <strong>live 3D mapping</strong> of the scene on the embedded computer of the robot, i.e. the <strong>NVIDIA Jetson TX2</strong>.</p>
<p><img src="../../img/3d-mapping/liborg.jpg" alt="Liborg"></p>
<p>In addition, we developed a system to transmit the reconstructed 3D model to a remote computer or server. The latter allows a number of additional applications for which the robot can be used such as live monitoring of the acquired 3D model, for instance to perform <strong>inspection or assess damages in areas that are difficult to reach</strong>. We made it possible to control the robot using a remote control and thus to define the area to be mapped.</p>
<p>Recently, we started the development of a truly autonomous system in a way that it will be possible for the robot to perform navigation based on its own acquired 3D model. This will allow the robot to perform the entire 3D mapping of a scene without any manual intervention.</p>
<p>The main sensor on the rover is a lidar scanner, hence the name Liborg. At a later stage we integrated a regular camera on the robot to be able to combine the 3D geometric information of the scene with visual data. To that end, a synchronisation module was developed along with calibration algorithms to relate the data of both sensors.</p>
<p>The work on Liborg has been published and presented at an international scientific conference. The rover was also demonstrated at the <strong>international technology forum (ITF)</strong> of imec in 2017 and 2018 as well as during the anniversary exhibition of Ghent University in 2017. The development of Liborg was also highlighted in the <strong>Imec magazine</strong> of October 2018 [<a href="https://www.imec-int.com/en/imec-magazine/imec-magazine-october-2018/liborg-2-0-a-robot-for-on-the-fly-3d-mapping-of-environments">link</a>].</p>

  </article>
</section>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js" id="MathJax-script"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'], ['\\(', '\\)']
        ],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>

      </div>

      
  <footer class="footer">
    <section class="container">
      
        <p>Computer science engineer & PhD in 3D computer vision with a strong interest in artificial intelligence and autonomous robots.</p>
      
      
        ©
        
        2020
         Michiel Vlaminck 
      
      
      
    </section>
  </footer>

    </main>

    

    

    

  </body>

</html>
